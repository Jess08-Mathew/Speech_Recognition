# -*- coding: utf-8 -*-
"""SPR-LAB-5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Y2JVrEZrIUDnrJF-lHQU_q71S8oIDv7a

Plot both speech signals to observe their differences in length and amplitude patterns.
"""

import numpy as np
import matplotlib.pyplot as plt

# Given speech signals
signal1 = np.array([0.2, 0.4, 0.6, 0.8, 1.0, 0.8, 0.6, 0.4, 0.2])  # Reference (faster)
signal2 = np.array([0.2, 0.3, 0.5, 0.7, 0.9, 1.0, 0.9, 0.7, 0.5, 0.4, 0.3, 0.2])  # Test (slower)

# Create time axes for plotting
t1 = np.linspace(0, 1, len(signal1))
t2 = np.linspace(0, 1, len(signal2))

# Plot both signals
plt.figure(figsize=(10, 5))
plt.plot(t1, signal1, 'o-', label='Signal 1 (Reference - Faster)')
plt.plot(t2, signal2, 'o-', label='Signal 2 (Test - Slower)')
plt.title("Comparison of Two Speech Signals")
plt.xlabel("Normalized Time")
plt.ylabel("Amplitude")
plt.legend()
plt.grid(True)
plt.show()

"""Signal 2 contains more samples than Signal 1, indicating that it takes a longer duration to represent the same word — hence reflecting slower speech.

The amplitude patterns of both signals are similar, but in Signal 2 they are stretched over time, showing that the same speech content is spoken more slowly.

Perform Linear Time Normalization on Signal 2 to match the length of Signal 1.
"""

import numpy as np
import matplotlib.pyplot as plt
from scipy.interpolate import interp1d

# Given signals
signal1 = np.array([0.2, 0.4, 0.6, 0.8, 1.0, 0.8, 0.6, 0.4, 0.2])  # Reference (faster)
signal2 = np.array([0.2, 0.3, 0.5, 0.7, 0.9, 1.0, 0.9, 0.7, 0.5, 0.4, 0.3, 0.2])  # Test (slower)

# Create normalized time axes
t1 = np.linspace(0, 1, len(signal1))
t2 = np.linspace(0, 1, len(signal2))

# --- Linear Time Normalization (Resampling) ---
# Interpolate Signal 2 to have the same number of samples as Signal 1
interp_func = interp1d(t2, signal2, kind='linear')
signal2_normalized = interp_func(t1)

# Plot original and normalized signals
plt.figure(figsize=(10, 5))
plt.plot(t1, signal1, 'o-', label='Signal 1 (Reference)')
plt.plot(t1, signal2_normalized, 'x--', label='Signal 2 (After LTN)')
plt.title("Linear Time Normalization: Signal 2 Adjusted to Match Signal 1")
plt.xlabel("Normalized Time")
plt.ylabel("Amplitude")
plt.legend()
plt.grid(True)
plt.show()

"""Linear Time Normalization is used to align two time-dependent signals (like speech, motion, or sensor data) that represent the same pattern or event but are stretched or compressed in time.

It adjusts the time axis of one signal so that both signals have the same duration and number of samples — allowing direct comparison of their shapes, amplitudes, and temporal features.

Compute the alignment between Signal 1 and the normalized Signal 2.
"""

# --- Compute alignment (Correlation) ---
correlation = np.corrcoef(signal1, signal2_normalized)[0, 1]
print(f"Correlation between Signal 1 and Normalized Signal 2: {correlation:.4f}")

"""The correlation value of 0.9690 confirms that Linear Time Normalization effectively aligns both speech signals, making their temporal patterns closely match.

Plot the alignment path, showing how each sample in Signal 1 corresponds to a sample in Signal 2.
"""

# --- Compute alignment path ---
# Each point in signal1 corresponds to a proportional point in signal2
alignment_indices_signal1 = np.arange(len(signal1))
alignment_indices_signal2 = np.linspace(0, len(signal2)-1, len(signal1))

# --- Plot alignment path ---
plt.figure(figsize=(6, 6))
plt.plot(alignment_indices_signal1, alignment_indices_signal2, 'o-', color='purple')
plt.title("Alignment Path Between Signal 1 and Signal 2")
plt.xlabel("Sample Index in Signal 1 (Reference)")
plt.ylabel("Corresponding Sample Index in Signal 2")
plt.grid(True)
plt.show()

"""The alignment path plot shows a straight line, indicating that each sample in Signal 1 corresponds linearly to a proportionate sample in Signal 2. This confirms that Linear Time Normalization applies a uniform time scaling between the two signals.

Write an inference on how Linear Time Normalization aligns the two speech signals.

# **Inference**

Linear Time Normalization aligns the two speech signals by uniformly scaling the time axis of Signal 2 so that it matches the length of Signal 1. This method assumes that the speed difference between the two signals is consistent throughout the entire duration. By interpolating Signal 2 to have the same number of samples as Signal 1, we effectively compress its time scale.

However, LTN may not account for non-linear variations in speaking speed within
different parts of the word. For example, if certain phonemes are elongated more than others, LTN may not perfectly align the signals. In such cases, more
sophisticated methods like Dynamic Time Warping (DTW) may provide better
alignment by allowing for non-linear mappings between the time axes of the signals.

Time-Domain Error Analysis
"""

from sklearn.metrics import mean_squared_error

mse_before = mean_squared_error(signal1, signal2[:len(signal1)])
mse_after = mean_squared_error(signal1, signal2_normalized)
print(f"MSE before LTN: {mse_before:.4f}")
print(f"MSE after LTN:  {mse_after:.4f}")

from mpl_toolkits.mplot3d import Axes3D

fig = plt.figure(figsize=(7,5))
ax = fig.add_subplot(111, projection='3d')
ax.plot(alignment_indices_signal1, alignment_indices_signal2, signal2_normalized, 'o-')
ax.set_title("3D Alignment Visualization")
ax.set_xlabel("Signal 1 Index")
ax.set_ylabel("Signal 2 Index")
ax.set_zlabel("Amplitude")
plt.show()

errors = (signal1 - signal2_normalized)**2
plt.plot(errors, 'r-o')
plt.title("Sample-wise Squared Error After LTN")
plt.xlabel("Sample Index")
plt.ylabel("Squared Error")
plt.grid(True)
plt.show()